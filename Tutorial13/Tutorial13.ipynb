{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NmnMINuUbNOf",
        "outputId": "16f9e08d-c729-4c0d-d3eb-dcfb93c6028e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mhwpZpRJbNOh"
      },
      "outputs": [],
      "source": [
        "import os.path as osp\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch_geometric.datasets import AMiner\n",
        "from torch_geometric.nn import MetaPath2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SySTRhupbNOi"
      },
      "source": [
        "# MetaPath2Vec\n",
        "\n",
        "[paper](https://ericdongyx.github.io/papers/KDD17-dong-chawla-swami-metapath2vec.pdf)  \n",
        "[code](https://github.com/rusty1s/pytorch_geometric/blob/master/examples/metapath2vec.py)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aco9tkyDbNOi"
      },
      "outputs": [],
      "source": [
        "# load the dataset\n",
        "path = osp.join('..', 'data', 'AMiner')\n",
        "dataset = AMiner(path)\n",
        "data = dataset[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DwRZ4UVbbNOj",
        "outputId": "96f4d2c7-2cd6-4cef-ce3e-ebc98a5ec21b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HeteroData(\n",
            "  author={\n",
            "    y=[246678],\n",
            "    y_index=[246678],\n",
            "    num_nodes=1693531,\n",
            "  },\n",
            "  venue={\n",
            "    y=[134],\n",
            "    y_index=[134],\n",
            "    num_nodes=3883,\n",
            "  },\n",
            "  paper={ num_nodes=3194405 },\n",
            "  (paper, written_by, author)={ edge_index=[2, 9323605] },\n",
            "  (author, writes, paper)={ edge_index=[2, 9323605] },\n",
            "  (paper, published_in, venue)={ edge_index=[2, 3194405] },\n",
            "  (venue, publishes, paper)={ edge_index=[2, 3194405] }\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PabHQWGQbNOk",
        "outputId": "d1e92d07-92d6-4167-ec17-cc57be8c9602",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dict'>\n",
            "tensor([[      0,       1,       2,  ..., 3194404, 3194404, 3194404],\n",
            "        [      0,       1,       2,  ...,    4393,   21681,  317436]])\n"
          ]
        }
      ],
      "source": [
        "print(type(data.edge_index_dict))\n",
        "print(data.edge_index_dict[('paper', 'written_by', 'author')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HRA9XFDEbNOk",
        "outputId": "bfeb58d3-764b-4e7b-b4db-9363d13c9690",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dict'>\n",
            "{'author': 1693531, 'venue': 3883, 'paper': 3194405}\n"
          ]
        }
      ],
      "source": [
        "print(type(data.num_nodes_dict))\n",
        "print(data.num_nodes_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "uKUkbtm4bNOk",
        "outputId": "d576f9b4-6fc4-416c-f1f6-fd2debaf2b58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dict'>\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5,\n",
            "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7,\n",
            "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7])\n"
          ]
        }
      ],
      "source": [
        "print(type(data.y_dict))\n",
        "print(data.y_dict[\"venue\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "HQiJrlMebNOl",
        "outputId": "7797e27f-bd6b-455e-80e2-1e8896b1cc50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dict'>\n",
            "tensor([1741, 2245,  111,  837, 2588, 2116, 2696, 3648, 3784,  313, 3414,  598,\n",
            "        2995, 2716, 1423,  783, 1902, 3132, 1753, 2748, 2660, 3182,  775, 3339,\n",
            "        1601, 3589,  156, 1145,  692, 3048,  925, 1587,  820, 1374, 3719,  819,\n",
            "         492, 3830, 2777, 3001, 3693,  517, 1808, 2353, 3499, 1763, 2372, 1030,\n",
            "         721, 2680, 3355, 1217, 3400, 1271, 1970, 1127,  407,  353, 1471, 1095,\n",
            "         477, 3701,   65, 1009, 1899, 1442, 2073, 3143, 2466,  289, 1996, 1070,\n",
            "        3871, 3695,  281, 3633,   50, 2642, 1925, 1285, 2587, 3814, 3582, 1873,\n",
            "        1339, 3450,  271, 2966,  453, 2638, 1354, 3211,  391, 1588, 3875, 2216,\n",
            "        2146, 3765, 2486,  661, 3367,  426,  750, 2158,  519,  230, 1677,  839,\n",
            "        2945, 1313, 1037, 2879, 2225, 3523, 1247,  448,  227, 3385,  529, 2849,\n",
            "        1584, 1229,  373, 2235, 1819, 1764, 3155, 2852, 2789, 3474, 1571, 2088,\n",
            "         208,  462])\n"
          ]
        }
      ],
      "source": [
        "print(type(data.y_index_dict))\n",
        "print(data.y_index_dict[\"venue\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bXx-VHXMbNOm"
      },
      "outputs": [],
      "source": [
        "# move the data to cpu or GPU\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device = \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "R3jIWPNzbNOm"
      },
      "outputs": [],
      "source": [
        "# define the model\n",
        "\n",
        "metapath = [\n",
        "    ('author', 'writes', 'paper'),\n",
        "    ('paper', 'published_in', 'venue'),\n",
        "    ('venue', 'publishes', 'paper'),\n",
        "    ('paper', 'written_by', 'author'),\n",
        "]\n",
        "\n",
        "\n",
        "model = MetaPath2Vec(data.edge_index_dict,\n",
        "                     embedding_dim=64,\n",
        "                     metapath=metapath,\n",
        "                     walk_length=3,\n",
        "                     context_size=3,\n",
        "                     walks_per_node=2,\n",
        "                     num_negative_samples=1,\n",
        "                     sparse=True\n",
        "                    ).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hH8SubFxbNOn"
      },
      "outputs": [],
      "source": [
        "# use the loader to build a loader\n",
        "loader = model.loader(batch_size=8, shuffle=True, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2JIiJ6tsbNOn",
        "outputId": "46f1794e-1f0a-4f7d-d057-0e296a5c2e03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 torch.Size([32, 3]) torch.Size([32, 3])\n",
            "1 torch.Size([32, 3]) torch.Size([32, 3])\n",
            "2 torch.Size([32, 3]) torch.Size([32, 3])\n",
            "3 torch.Size([32, 3]) torch.Size([32, 3])\n",
            "4 torch.Size([32, 3]) torch.Size([32, 3])\n",
            "5 torch.Size([32, 3]) torch.Size([32, 3])\n",
            "6 torch.Size([32, 3]) torch.Size([32, 3])\n",
            "7 torch.Size([32, 3]) torch.Size([32, 3])\n",
            "8 torch.Size([32, 3]) torch.Size([32, 3])\n",
            "9 torch.Size([32, 3]) torch.Size([32, 3])\n"
          ]
        }
      ],
      "source": [
        "for idx, (pos_rw, neg_rw) in enumerate(loader):\n",
        "    if idx == 10: break\n",
        "    print(idx, pos_rw.shape, neg_rw.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "afZ1ZBbkbNOn",
        "outputId": "07391d07-1de3-49d3-9de9-aafc3b13deb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1205330, 3825978, 4888163]) tensor([1205330, 1710189, 4890038])\n"
          ]
        }
      ],
      "source": [
        "print(pos_rw[0],neg_rw[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "cxcuxCugbNOn"
      },
      "outputs": [],
      "source": [
        "# Inizialize optimizer\n",
        "optimizer = torch.optim.SparseAdam(list(model.parameters()), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "mDieig6MbNOo"
      },
      "outputs": [],
      "source": [
        "def train(epoch, log_steps=500, eval_steps=1000):\n",
        "    model.train()\n",
        "\n",
        "    total_loss = 0\n",
        "    for i, (pos_rw, neg_rw) in enumerate(loader):\n",
        "        optimizer.zero_grad()\n",
        "        loss = model.loss(pos_rw.to(device), neg_rw.to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        if (i + 1) % log_steps == 0:\n",
        "            print((f'Epoch: {epoch}, Step: {i + 1:05d}/{len(loader)}, '\n",
        "                   f'Loss: {total_loss / log_steps:.4f}'))\n",
        "            total_loss = 0\n",
        "\n",
        "        if (i + 1) % eval_steps == 0:\n",
        "            acc = test()\n",
        "            print((f'Epoch: {epoch}, Step: {i + 1:05d}/{len(loader)}, '\n",
        "                   f'Acc: {acc:.4f}'))\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(train_ratio=0.05):\n",
        "    model.eval()\n",
        "\n",
        "    z = model('author', batch=data.y_index_dict['author'])\n",
        "    y = data.y_dict['author']\n",
        "\n",
        "    perm = torch.randperm(z.size(0))\n",
        "    train_perm = perm[:int(z.size(0) * train_ratio)]\n",
        "    test_perm = perm[int(z.size(0) * train_ratio):]\n",
        "\n",
        "    return model.test(z[train_perm], y[train_perm], z[test_perm],\n",
        "                      y[test_perm], max_iter=150)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kNFOxcshbNOo",
        "outputId": "e5cf09cd-fcba-4d98-cb78-842cd5e07fe6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Step: 00500/211692, Loss: 6.7550\n",
            "Epoch: 1, Step: 01000/211692, Loss: 6.6990\n",
            "Epoch: 1, Step: 01000/211692, Acc: 0.2748\n",
            "Epoch: 1, Step: 01500/211692, Loss: 6.6744\n",
            "Epoch: 1, Step: 02000/211692, Loss: 6.6113\n",
            "Epoch: 1, Step: 02000/211692, Acc: 0.2763\n",
            "Epoch: 1, Step: 02500/211692, Loss: 6.5909\n",
            "Epoch: 1, Step: 03000/211692, Loss: 6.5548\n",
            "Epoch: 1, Step: 03000/211692, Acc: 0.2768\n",
            "Epoch: 1, Step: 03500/211692, Loss: 6.3693\n",
            "Epoch: 1, Step: 04000/211692, Loss: 6.3233\n",
            "Epoch: 1, Step: 04000/211692, Acc: 0.2763\n",
            "Epoch: 1, Step: 04500/211692, Loss: 6.3255\n",
            "Epoch: 1, Step: 05000/211692, Loss: 6.2131\n",
            "Epoch: 1, Step: 05000/211692, Acc: 0.2759\n",
            "Epoch: 1, Step: 05500/211692, Loss: 6.2407\n",
            "Epoch: 1, Step: 06000/211692, Loss: 6.1743\n",
            "Epoch: 1, Step: 06000/211692, Acc: 0.2748\n",
            "Epoch: 1, Step: 06500/211692, Loss: 6.1509\n",
            "Epoch: 1, Step: 07000/211692, Loss: 6.1135\n",
            "Epoch: 1, Step: 07000/211692, Acc: 0.2748\n",
            "Epoch: 1, Step: 07500/211692, Loss: 5.9819\n",
            "Epoch: 1, Step: 08000/211692, Loss: 6.0341\n",
            "Epoch: 1, Step: 08000/211692, Acc: 0.2770\n",
            "Epoch: 1, Step: 08500/211692, Loss: 5.9884\n",
            "Epoch: 1, Step: 09000/211692, Loss: 5.9375\n",
            "Epoch: 1, Step: 09000/211692, Acc: 0.2763\n",
            "Epoch: 1, Step: 09500/211692, Loss: 5.8404\n",
            "Epoch: 1, Step: 10000/211692, Loss: 5.8671\n",
            "Epoch: 1, Step: 10000/211692, Acc: 0.2758\n",
            "Epoch: 1, Step: 10500/211692, Loss: 5.8305\n",
            "Epoch: 1, Step: 11000/211692, Loss: 5.7779\n",
            "Epoch: 1, Step: 11000/211692, Acc: 0.2772\n",
            "Epoch: 1, Step: 11500/211692, Loss: 5.7414\n",
            "Epoch: 1, Step: 12000/211692, Loss: 5.6797\n",
            "Epoch: 1, Step: 12000/211692, Acc: 0.2739\n",
            "Epoch: 1, Step: 12500/211692, Loss: 5.7314\n",
            "Epoch: 1, Step: 13000/211692, Loss: 5.6953\n",
            "Epoch: 1, Step: 13000/211692, Acc: 0.2764\n",
            "Epoch: 1, Step: 13500/211692, Loss: 5.6814\n",
            "Epoch: 1, Step: 14000/211692, Loss: 5.6973\n",
            "Epoch: 1, Step: 14000/211692, Acc: 0.2770\n",
            "Epoch: 1, Step: 14500/211692, Loss: 5.5911\n",
            "Epoch: 1, Step: 15000/211692, Loss: 5.5853\n",
            "Epoch: 1, Step: 15000/211692, Acc: 0.2774\n",
            "Epoch: 1, Step: 15500/211692, Loss: 5.6035\n",
            "Epoch: 1, Step: 16000/211692, Loss: 5.5158\n",
            "Epoch: 1, Step: 16000/211692, Acc: 0.2767\n",
            "Epoch: 1, Step: 16500/211692, Loss: 5.4614\n",
            "Epoch: 1, Step: 17000/211692, Loss: 5.4256\n",
            "Epoch: 1, Step: 17000/211692, Acc: 0.2771\n",
            "Epoch: 1, Step: 17500/211692, Loss: 5.4315\n",
            "Epoch: 1, Step: 18000/211692, Loss: 5.4069\n",
            "Epoch: 1, Step: 18000/211692, Acc: 0.2768\n",
            "Epoch: 1, Step: 18500/211692, Loss: 5.4255\n",
            "Epoch: 1, Step: 19000/211692, Loss: 5.4785\n",
            "Epoch: 1, Step: 19000/211692, Acc: 0.2765\n",
            "Epoch: 1, Step: 19500/211692, Loss: 5.3799\n",
            "Epoch: 1, Step: 20000/211692, Loss: 5.4103\n",
            "Epoch: 1, Step: 20000/211692, Acc: 0.2753\n",
            "Epoch: 1, Step: 20500/211692, Loss: 5.3100\n",
            "Epoch: 1, Step: 21000/211692, Loss: 5.3642\n",
            "Epoch: 1, Step: 21000/211692, Acc: 0.2778\n",
            "Epoch: 1, Step: 21500/211692, Loss: 5.2509\n",
            "Epoch: 1, Step: 22000/211692, Loss: 5.2804\n",
            "Epoch: 1, Step: 22000/211692, Acc: 0.2772\n",
            "Epoch: 1, Step: 22500/211692, Loss: 5.2564\n",
            "Epoch: 1, Step: 23000/211692, Loss: 5.2919\n",
            "Epoch: 1, Step: 23000/211692, Acc: 0.2767\n",
            "Epoch: 1, Step: 23500/211692, Loss: 5.2014\n",
            "Epoch: 1, Step: 24000/211692, Loss: 5.2002\n",
            "Epoch: 1, Step: 24000/211692, Acc: 0.2759\n",
            "Epoch: 1, Step: 24500/211692, Loss: 5.1253\n",
            "Epoch: 1, Step: 25000/211692, Loss: 5.1395\n",
            "Epoch: 1, Step: 25000/211692, Acc: 0.2773\n",
            "Epoch: 1, Step: 25500/211692, Loss: 5.1947\n",
            "Epoch: 1, Step: 26000/211692, Loss: 5.0887\n",
            "Epoch: 1, Step: 26000/211692, Acc: 0.2753\n",
            "Epoch: 1, Step: 26500/211692, Loss: 5.1621\n",
            "Epoch: 1, Step: 27000/211692, Loss: 5.1686\n",
            "Epoch: 1, Step: 27000/211692, Acc: 0.2776\n",
            "Epoch: 1, Step: 27500/211692, Loss: 5.0729\n",
            "Epoch: 1, Step: 28000/211692, Loss: 5.1014\n",
            "Epoch: 1, Step: 28000/211692, Acc: 0.2770\n",
            "Epoch: 1, Step: 28500/211692, Loss: 5.0782\n",
            "Epoch: 1, Step: 29000/211692, Loss: 4.9998\n",
            "Epoch: 1, Step: 29000/211692, Acc: 0.2753\n",
            "Epoch: 1, Step: 29500/211692, Loss: 4.9941\n",
            "Epoch: 1, Step: 30000/211692, Loss: 5.0190\n",
            "Epoch: 1, Step: 30000/211692, Acc: 0.2766\n",
            "Epoch: 1, Step: 30500/211692, Loss: 5.0355\n",
            "Epoch: 1, Step: 31000/211692, Loss: 4.9436\n",
            "Epoch: 1, Step: 31000/211692, Acc: 0.2747\n",
            "Epoch: 1, Step: 31500/211692, Loss: 4.8948\n",
            "Epoch: 1, Step: 32000/211692, Loss: 4.9837\n",
            "Epoch: 1, Step: 32000/211692, Acc: 0.2763\n",
            "Epoch: 1, Step: 32500/211692, Loss: 4.9699\n",
            "Epoch: 1, Step: 33000/211692, Loss: 4.9490\n",
            "Epoch: 1, Step: 33000/211692, Acc: 0.2773\n",
            "Epoch: 1, Step: 33500/211692, Loss: 4.9219\n",
            "Epoch: 1, Step: 34000/211692, Loss: 4.9320\n",
            "Epoch: 1, Step: 34000/211692, Acc: 0.2739\n",
            "Epoch: 1, Step: 34500/211692, Loss: 4.9064\n",
            "Epoch: 1, Step: 35000/211692, Loss: 4.9100\n",
            "Epoch: 1, Step: 35000/211692, Acc: 0.2752\n",
            "Epoch: 1, Step: 35500/211692, Loss: 4.9344\n",
            "Epoch: 1, Step: 36000/211692, Loss: 4.8971\n",
            "Epoch: 1, Step: 36000/211692, Acc: 0.2763\n",
            "Epoch: 1, Step: 36500/211692, Loss: 4.8250\n",
            "Epoch: 1, Step: 37000/211692, Loss: 4.8661\n",
            "Epoch: 1, Step: 37000/211692, Acc: 0.2744\n",
            "Epoch: 1, Step: 37500/211692, Loss: 4.8382\n",
            "Epoch: 1, Step: 38000/211692, Loss: 4.8014\n",
            "Epoch: 1, Step: 38000/211692, Acc: 0.2755\n",
            "Epoch: 1, Step: 38500/211692, Loss: 4.7550\n",
            "Epoch: 1, Step: 39000/211692, Loss: 4.7680\n",
            "Epoch: 1, Step: 39000/211692, Acc: 0.2759\n",
            "Epoch: 1, Step: 39500/211692, Loss: 4.8363\n",
            "Epoch: 1, Step: 40000/211692, Loss: 4.7794\n",
            "Epoch: 1, Step: 40000/211692, Acc: 0.2765\n",
            "Epoch: 1, Step: 40500/211692, Loss: 4.8212\n",
            "Epoch: 1, Step: 41000/211692, Loss: 4.7862\n",
            "Epoch: 1, Step: 41000/211692, Acc: 0.2768\n",
            "Epoch: 1, Step: 41500/211692, Loss: 4.7674\n",
            "Epoch: 1, Step: 42000/211692, Loss: 4.7853\n",
            "Epoch: 1, Step: 42000/211692, Acc: 0.2774\n",
            "Epoch: 1, Step: 42500/211692, Loss: 4.7009\n",
            "Epoch: 1, Step: 43000/211692, Loss: 4.7500\n",
            "Epoch: 1, Step: 43000/211692, Acc: 0.2769\n",
            "Epoch: 1, Step: 43500/211692, Loss: 4.6857\n",
            "Epoch: 1, Step: 44000/211692, Loss: 4.7532\n",
            "Epoch: 1, Step: 44000/211692, Acc: 0.2758\n",
            "Epoch: 1, Step: 44500/211692, Loss: 4.7212\n",
            "Epoch: 1, Step: 45000/211692, Loss: 4.6781\n",
            "Epoch: 1, Step: 45000/211692, Acc: 0.2761\n",
            "Epoch: 1, Step: 45500/211692, Loss: 4.7191\n",
            "Epoch: 1, Step: 46000/211692, Loss: 4.6988\n",
            "Epoch: 1, Step: 46000/211692, Acc: 0.2764\n",
            "Epoch: 1, Step: 46500/211692, Loss: 4.6398\n",
            "Epoch: 1, Step: 47000/211692, Loss: 4.6621\n",
            "Epoch: 1, Step: 47000/211692, Acc: 0.2760\n",
            "Epoch: 1, Step: 47500/211692, Loss: 4.7091\n",
            "Epoch: 1, Step: 48000/211692, Loss: 4.6817\n",
            "Epoch: 1, Step: 48000/211692, Acc: 0.2751\n",
            "Epoch: 1, Step: 48500/211692, Loss: 4.6162\n",
            "Epoch: 1, Step: 49000/211692, Loss: 4.6265\n",
            "Epoch: 1, Step: 49000/211692, Acc: 0.2734\n",
            "Epoch: 1, Step: 49500/211692, Loss: 4.6120\n",
            "Epoch: 1, Step: 50000/211692, Loss: 4.6270\n",
            "Epoch: 1, Step: 50000/211692, Acc: 0.2765\n",
            "Epoch: 1, Step: 50500/211692, Loss: 4.5619\n",
            "Epoch: 1, Step: 51000/211692, Loss: 4.6114\n",
            "Epoch: 1, Step: 51000/211692, Acc: 0.2749\n",
            "Epoch: 1, Step: 51500/211692, Loss: 4.5723\n",
            "Epoch: 1, Step: 52000/211692, Loss: 4.5686\n",
            "Epoch: 1, Step: 52000/211692, Acc: 0.2747\n",
            "Epoch: 1, Step: 52500/211692, Loss: 4.4953\n",
            "Epoch: 1, Step: 53000/211692, Loss: 4.5434\n",
            "Epoch: 1, Step: 53000/211692, Acc: 0.2763\n",
            "Epoch: 1, Step: 53500/211692, Loss: 4.5772\n",
            "Epoch: 1, Step: 54000/211692, Loss: 4.5176\n",
            "Epoch: 1, Step: 54000/211692, Acc: 0.2763\n",
            "Epoch: 1, Step: 54500/211692, Loss: 4.5995\n",
            "Epoch: 1, Step: 55000/211692, Loss: 4.5658\n",
            "Epoch: 1, Step: 55000/211692, Acc: 0.2754\n",
            "Epoch: 1, Step: 55500/211692, Loss: 4.5578\n",
            "Epoch: 1, Step: 56000/211692, Loss: 4.5751\n",
            "Epoch: 1, Step: 56000/211692, Acc: 0.2766\n",
            "Epoch: 1, Step: 56500/211692, Loss: 4.5655\n",
            "Epoch: 1, Step: 57000/211692, Loss: 4.5167\n",
            "Epoch: 1, Step: 57000/211692, Acc: 0.2765\n",
            "Epoch: 1, Step: 57500/211692, Loss: 4.4961\n",
            "Epoch: 1, Step: 58000/211692, Loss: 4.5372\n",
            "Epoch: 1, Step: 58000/211692, Acc: 0.2768\n",
            "Epoch: 1, Step: 58500/211692, Loss: 4.5286\n",
            "Epoch: 1, Step: 59000/211692, Loss: 4.4240\n",
            "Epoch: 1, Step: 59000/211692, Acc: 0.2749\n",
            "Epoch: 1, Step: 59500/211692, Loss: 4.5052\n",
            "Epoch: 1, Step: 60000/211692, Loss: 4.4423\n",
            "Epoch: 1, Step: 60000/211692, Acc: 0.2767\n",
            "Epoch: 1, Step: 60500/211692, Loss: 4.4598\n",
            "Epoch: 1, Step: 61000/211692, Loss: 4.4533\n",
            "Epoch: 1, Step: 61000/211692, Acc: 0.2753\n",
            "Epoch: 1, Step: 61500/211692, Loss: 4.4723\n",
            "Epoch: 1, Step: 62000/211692, Loss: 4.4491\n",
            "Epoch: 1, Step: 62000/211692, Acc: 0.2765\n",
            "Epoch: 1, Step: 62500/211692, Loss: 4.4681\n",
            "Epoch: 1, Step: 63000/211692, Loss: 4.4013\n",
            "Epoch: 1, Step: 63000/211692, Acc: 0.2765\n",
            "Epoch: 1, Step: 63500/211692, Loss: 4.4635\n",
            "Epoch: 1, Step: 64000/211692, Loss: 4.4422\n",
            "Epoch: 1, Step: 64000/211692, Acc: 0.2763\n",
            "Epoch: 1, Step: 64500/211692, Loss: 4.4304\n",
            "Epoch: 1, Step: 65000/211692, Loss: 4.3714\n",
            "Epoch: 1, Step: 65000/211692, Acc: 0.2761\n",
            "Epoch: 1, Step: 65500/211692, Loss: 4.3949\n",
            "Epoch: 1, Step: 66000/211692, Loss: 4.4451\n",
            "Epoch: 1, Step: 66000/211692, Acc: 0.2765\n",
            "Epoch: 1, Step: 66500/211692, Loss: 4.3975\n",
            "Epoch: 1, Step: 67000/211692, Loss: 4.4700\n",
            "Epoch: 1, Step: 67000/211692, Acc: 0.2776\n",
            "Epoch: 1, Step: 67500/211692, Loss: 4.4031\n",
            "Epoch: 1, Step: 68000/211692, Loss: 4.3899\n",
            "Epoch: 1, Step: 68000/211692, Acc: 0.2760\n",
            "Epoch: 1, Step: 68500/211692, Loss: 4.3737\n",
            "Epoch: 1, Step: 69000/211692, Loss: 4.3799\n",
            "Epoch: 1, Step: 69000/211692, Acc: 0.2770\n",
            "Epoch: 1, Step: 69500/211692, Loss: 4.3723\n",
            "Epoch: 1, Step: 70000/211692, Loss: 4.4120\n",
            "Epoch: 1, Step: 70000/211692, Acc: 0.2772\n",
            "Epoch: 1, Step: 70500/211692, Loss: 4.4130\n",
            "Epoch: 1, Step: 71000/211692, Loss: 4.3685\n",
            "Epoch: 1, Step: 71000/211692, Acc: 0.2726\n",
            "Epoch: 1, Step: 71500/211692, Loss: 4.3549\n",
            "Epoch: 1, Step: 72000/211692, Loss: 4.3957\n",
            "Epoch: 1, Step: 72000/211692, Acc: 0.2752\n",
            "Epoch: 1, Step: 72500/211692, Loss: 4.3592\n",
            "Epoch: 1, Step: 73000/211692, Loss: 4.3279\n",
            "Epoch: 1, Step: 73000/211692, Acc: 0.2754\n",
            "Epoch: 1, Step: 73500/211692, Loss: 4.3310\n",
            "Epoch: 1, Step: 74000/211692, Loss: 4.3848\n",
            "Epoch: 1, Step: 74000/211692, Acc: 0.2765\n",
            "Epoch: 1, Step: 74500/211692, Loss: 4.3283\n",
            "Epoch: 1, Step: 75000/211692, Loss: 4.3879\n",
            "Epoch: 1, Step: 75000/211692, Acc: 0.2747\n",
            "Epoch: 1, Step: 75500/211692, Loss: 4.3209\n",
            "Epoch: 1, Step: 76000/211692, Loss: 4.3314\n",
            "Epoch: 1, Step: 76000/211692, Acc: 0.2759\n",
            "Epoch: 1, Step: 76500/211692, Loss: 4.3084\n",
            "Epoch: 1, Step: 77000/211692, Loss: 4.3424\n",
            "Epoch: 1, Step: 77000/211692, Acc: 0.2731\n",
            "Epoch: 1, Step: 77500/211692, Loss: 4.3193\n",
            "Epoch: 1, Step: 78000/211692, Loss: 4.3052\n",
            "Epoch: 1, Step: 78000/211692, Acc: 0.2740\n",
            "Epoch: 1, Step: 78500/211692, Loss: 4.3298\n",
            "Epoch: 1, Step: 79000/211692, Loss: 4.2687\n",
            "Epoch: 1, Step: 79000/211692, Acc: 0.2761\n",
            "Epoch: 1, Step: 79500/211692, Loss: 4.3039\n",
            "Epoch: 1, Step: 80000/211692, Loss: 4.3370\n",
            "Epoch: 1, Step: 80000/211692, Acc: 0.2774\n",
            "Epoch: 1, Step: 80500/211692, Loss: 4.3469\n",
            "Epoch: 1, Step: 81000/211692, Loss: 4.2862\n",
            "Epoch: 1, Step: 81000/211692, Acc: 0.2769\n",
            "Epoch: 1, Step: 81500/211692, Loss: 4.3077\n",
            "Epoch: 1, Step: 82000/211692, Loss: 4.3694\n",
            "Epoch: 1, Step: 82000/211692, Acc: 0.2761\n",
            "Epoch: 1, Step: 82500/211692, Loss: 4.2757\n",
            "Epoch: 1, Step: 83000/211692, Loss: 4.2971\n",
            "Epoch: 1, Step: 83000/211692, Acc: 0.2765\n",
            "Epoch: 1, Step: 83500/211692, Loss: 4.3061\n",
            "Epoch: 1, Step: 84000/211692, Loss: 4.3016\n",
            "Epoch: 1, Step: 84000/211692, Acc: 0.2756\n",
            "Epoch: 1, Step: 84500/211692, Loss: 4.2784\n",
            "Epoch: 1, Step: 85000/211692, Loss: 4.3011\n",
            "Epoch: 1, Step: 85000/211692, Acc: 0.2763\n",
            "Epoch: 1, Step: 85500/211692, Loss: 4.3023\n",
            "Epoch: 1, Step: 86000/211692, Loss: 4.2590\n",
            "Epoch: 1, Step: 86000/211692, Acc: 0.2757\n",
            "Epoch: 1, Step: 86500/211692, Loss: 4.3010\n",
            "Epoch: 1, Step: 87000/211692, Loss: 4.3005\n",
            "Epoch: 1, Step: 87000/211692, Acc: 0.2767\n",
            "Epoch: 1, Step: 87500/211692, Loss: 4.2536\n",
            "Epoch: 1, Step: 88000/211692, Loss: 4.2289\n",
            "Epoch: 1, Step: 88000/211692, Acc: 0.2763\n",
            "Epoch: 1, Step: 88500/211692, Loss: 4.2854\n",
            "Epoch: 1, Step: 89000/211692, Loss: 4.3033\n",
            "Epoch: 1, Step: 89000/211692, Acc: 0.2742\n",
            "Epoch: 1, Step: 89500/211692, Loss: 4.2656\n",
            "Epoch: 1, Step: 90000/211692, Loss: 4.2317\n",
            "Epoch: 1, Step: 90000/211692, Acc: 0.2741\n",
            "Epoch: 1, Step: 90500/211692, Loss: 4.2763\n",
            "Epoch: 1, Step: 91000/211692, Loss: 4.2685\n",
            "Epoch: 1, Step: 91000/211692, Acc: 0.2755\n",
            "Epoch: 1, Step: 91500/211692, Loss: 4.1988\n",
            "Epoch: 1, Step: 92000/211692, Loss: 4.2687\n",
            "Epoch: 1, Step: 92000/211692, Acc: 0.2767\n",
            "Epoch: 1, Step: 92500/211692, Loss: 4.2522\n",
            "Epoch: 1, Step: 93000/211692, Loss: 4.2243\n",
            "Epoch: 1, Step: 93000/211692, Acc: 0.2740\n",
            "Epoch: 1, Step: 93500/211692, Loss: 4.2441\n",
            "Epoch: 1, Step: 94000/211692, Loss: 4.2009\n",
            "Epoch: 1, Step: 94000/211692, Acc: 0.2773\n",
            "Epoch: 1, Step: 94500/211692, Loss: 4.1959\n",
            "Epoch: 1, Step: 95000/211692, Loss: 4.2501\n",
            "Epoch: 1, Step: 95000/211692, Acc: 0.2755\n",
            "Epoch: 1, Step: 95500/211692, Loss: 4.2506\n",
            "Epoch: 1, Step: 96000/211692, Loss: 4.2308\n",
            "Epoch: 1, Step: 96000/211692, Acc: 0.2740\n",
            "Epoch: 1, Step: 96500/211692, Loss: 4.2540\n",
            "Epoch: 1, Step: 97000/211692, Loss: 4.1919\n",
            "Epoch: 1, Step: 97000/211692, Acc: 0.2762\n",
            "Epoch: 1, Step: 97500/211692, Loss: 4.2457\n",
            "Epoch: 1, Step: 98000/211692, Loss: 4.2236\n",
            "Epoch: 1, Step: 98000/211692, Acc: 0.2776\n",
            "Epoch: 1, Step: 98500/211692, Loss: 4.2452\n",
            "Epoch: 1, Step: 99000/211692, Loss: 4.2528\n",
            "Epoch: 1, Step: 99000/211692, Acc: 0.2771\n",
            "Epoch: 1, Step: 99500/211692, Loss: 4.2513\n",
            "Epoch: 1, Step: 100000/211692, Loss: 4.2395\n",
            "Epoch: 1, Step: 100000/211692, Acc: 0.2764\n",
            "Epoch: 1, Step: 100500/211692, Loss: 4.2240\n",
            "Epoch: 1, Step: 101000/211692, Loss: 4.2085\n",
            "Epoch: 1, Step: 101000/211692, Acc: 0.2761\n",
            "Epoch: 1, Step: 101500/211692, Loss: 4.1582\n",
            "Epoch: 1, Step: 102000/211692, Loss: 4.1882\n",
            "Epoch: 1, Step: 102000/211692, Acc: 0.2754\n",
            "Epoch: 1, Step: 102500/211692, Loss: 4.2037\n",
            "Epoch: 1, Step: 103000/211692, Loss: 4.1810\n",
            "Epoch: 1, Step: 103000/211692, Acc: 0.2747\n",
            "Epoch: 1, Step: 103500/211692, Loss: 4.1758\n",
            "Epoch: 1, Step: 104000/211692, Loss: 4.2583\n",
            "Epoch: 1, Step: 104000/211692, Acc: 0.2769\n",
            "Epoch: 1, Step: 104500/211692, Loss: 4.2123\n",
            "Epoch: 1, Step: 105000/211692, Loss: 4.1971\n",
            "Epoch: 1, Step: 105000/211692, Acc: 0.2773\n",
            "Epoch: 1, Step: 105500/211692, Loss: 4.1803\n",
            "Epoch: 1, Step: 106000/211692, Loss: 4.1858\n",
            "Epoch: 1, Step: 106000/211692, Acc: 0.2756\n",
            "Epoch: 1, Step: 106500/211692, Loss: 4.1391\n",
            "Epoch: 1, Step: 107000/211692, Loss: 4.2125\n",
            "Epoch: 1, Step: 107000/211692, Acc: 0.2763\n",
            "Epoch: 1, Step: 107500/211692, Loss: 4.2312\n",
            "Epoch: 1, Step: 108000/211692, Loss: 4.1746\n",
            "Epoch: 1, Step: 108000/211692, Acc: 0.2775\n",
            "Epoch: 1, Step: 108500/211692, Loss: 4.1642\n",
            "Epoch: 1, Step: 109000/211692, Loss: 4.2345\n",
            "Epoch: 1, Step: 109000/211692, Acc: 0.2758\n",
            "Epoch: 1, Step: 109500/211692, Loss: 4.2259\n",
            "Epoch: 1, Step: 110000/211692, Loss: 4.2683\n",
            "Epoch: 1, Step: 110000/211692, Acc: 0.2769\n",
            "Epoch: 1, Step: 110500/211692, Loss: 4.1586\n",
            "Epoch: 1, Step: 111000/211692, Loss: 4.2535\n",
            "Epoch: 1, Step: 111000/211692, Acc: 0.2734\n",
            "Epoch: 1, Step: 111500/211692, Loss: 4.1466\n",
            "Epoch: 1, Step: 112000/211692, Loss: 4.1838\n",
            "Epoch: 1, Step: 112000/211692, Acc: 0.2768\n",
            "Epoch: 1, Step: 112500/211692, Loss: 4.2184\n",
            "Epoch: 1, Step: 113000/211692, Loss: 4.2161\n",
            "Epoch: 1, Step: 113000/211692, Acc: 0.2763\n",
            "Epoch: 1, Step: 113500/211692, Loss: 4.1808\n",
            "Epoch: 1, Step: 114000/211692, Loss: 4.2081\n",
            "Epoch: 1, Step: 114000/211692, Acc: 0.2753\n",
            "Epoch: 1, Step: 114500/211692, Loss: 4.1103\n",
            "Epoch: 1, Step: 115000/211692, Loss: 4.1930\n",
            "Epoch: 1, Step: 115000/211692, Acc: 0.2759\n",
            "Epoch: 1, Step: 115500/211692, Loss: 4.1785\n",
            "Epoch: 1, Step: 116000/211692, Loss: 4.1860\n",
            "Epoch: 1, Step: 116000/211692, Acc: 0.2774\n",
            "Epoch: 1, Step: 116500/211692, Loss: 4.2030\n",
            "Epoch: 1, Step: 117000/211692, Loss: 4.2096\n",
            "Epoch: 1, Step: 117000/211692, Acc: 0.2765\n",
            "Epoch: 1, Step: 117500/211692, Loss: 4.1808\n",
            "Epoch: 1, Step: 118000/211692, Loss: 4.1641\n",
            "Epoch: 1, Step: 118000/211692, Acc: 0.2769\n",
            "Epoch: 1, Step: 118500/211692, Loss: 4.1885\n",
            "Epoch: 1, Step: 119000/211692, Loss: 4.1737\n",
            "Epoch: 1, Step: 119000/211692, Acc: 0.2758\n",
            "Epoch: 1, Step: 119500/211692, Loss: 4.0990\n",
            "Epoch: 1, Step: 120000/211692, Loss: 4.2026\n",
            "Epoch: 1, Step: 120000/211692, Acc: 0.2776\n",
            "Epoch: 1, Step: 120500/211692, Loss: 4.1769\n",
            "Epoch: 1, Step: 121000/211692, Loss: 4.2289\n",
            "Epoch: 1, Step: 121000/211692, Acc: 0.2763\n",
            "Epoch: 1, Step: 121500/211692, Loss: 4.1643\n",
            "Epoch: 1, Step: 122000/211692, Loss: 4.1885\n",
            "Epoch: 1, Step: 122000/211692, Acc: 0.2770\n",
            "Epoch: 1, Step: 122500/211692, Loss: 4.1918\n",
            "Epoch: 1, Step: 123000/211692, Loss: 4.1476\n",
            "Epoch: 1, Step: 123000/211692, Acc: 0.2761\n",
            "Epoch: 1, Step: 123500/211692, Loss: 4.1412\n",
            "Epoch: 1, Step: 124000/211692, Loss: 4.1790\n",
            "Epoch: 1, Step: 124000/211692, Acc: 0.2760\n",
            "Epoch: 1, Step: 124500/211692, Loss: 4.1632\n",
            "Epoch: 1, Step: 125000/211692, Loss: 4.2084\n",
            "Epoch: 1, Step: 125000/211692, Acc: 0.2758\n",
            "Epoch: 1, Step: 125500/211692, Loss: 4.1058\n",
            "Epoch: 1, Step: 126000/211692, Loss: 4.1642\n",
            "Epoch: 1, Step: 126000/211692, Acc: 0.2758\n",
            "Epoch: 1, Step: 126500/211692, Loss: 4.1315\n",
            "Epoch: 1, Step: 127000/211692, Loss: 4.1279\n",
            "Epoch: 1, Step: 127000/211692, Acc: 0.2770\n",
            "Epoch: 1, Step: 127500/211692, Loss: 4.1483\n",
            "Epoch: 1, Step: 128000/211692, Loss: 4.1549\n",
            "Epoch: 1, Step: 128000/211692, Acc: 0.2724\n",
            "Epoch: 1, Step: 128500/211692, Loss: 4.1476\n",
            "Epoch: 1, Step: 129000/211692, Loss: 4.1950\n",
            "Epoch: 1, Step: 129000/211692, Acc: 0.2758\n",
            "Epoch: 1, Step: 129500/211692, Loss: 4.1429\n",
            "Epoch: 1, Step: 130000/211692, Loss: 4.1839\n",
            "Epoch: 1, Step: 130000/211692, Acc: 0.2753\n",
            "Epoch: 1, Step: 130500/211692, Loss: 4.1370\n",
            "Epoch: 1, Step: 131000/211692, Loss: 4.1355\n",
            "Epoch: 1, Step: 131000/211692, Acc: 0.2751\n",
            "Epoch: 1, Step: 131500/211692, Loss: 4.2001\n",
            "Epoch: 1, Step: 132000/211692, Loss: 4.1301\n",
            "Epoch: 1, Step: 132000/211692, Acc: 0.2761\n",
            "Epoch: 1, Step: 132500/211692, Loss: 4.1109\n",
            "Epoch: 1, Step: 133000/211692, Loss: 4.1595\n",
            "Epoch: 1, Step: 133000/211692, Acc: 0.2771\n",
            "Epoch: 1, Step: 133500/211692, Loss: 4.1461\n",
            "Epoch: 1, Step: 134000/211692, Loss: 4.1388\n",
            "Epoch: 1, Step: 134000/211692, Acc: 0.2758\n",
            "Epoch: 1, Step: 134500/211692, Loss: 4.2100\n",
            "Epoch: 1, Step: 135000/211692, Loss: 4.1410\n",
            "Epoch: 1, Step: 135000/211692, Acc: 0.2744\n",
            "Epoch: 1, Step: 135500/211692, Loss: 4.1719\n",
            "Epoch: 1, Step: 136000/211692, Loss: 4.1865\n",
            "Epoch: 1, Step: 136000/211692, Acc: 0.2765\n",
            "Epoch: 1, Step: 136500/211692, Loss: 4.1794\n",
            "Epoch: 1, Step: 137000/211692, Loss: 4.1259\n",
            "Epoch: 1, Step: 137000/211692, Acc: 0.2774\n",
            "Epoch: 1, Step: 137500/211692, Loss: 4.1481\n",
            "Epoch: 1, Step: 138000/211692, Loss: 4.1707\n",
            "Epoch: 1, Step: 138000/211692, Acc: 0.2767\n",
            "Epoch: 1, Step: 138500/211692, Loss: 4.1554\n",
            "Epoch: 1, Step: 139000/211692, Loss: 4.1581\n",
            "Epoch: 1, Step: 139000/211692, Acc: 0.2745\n",
            "Epoch: 1, Step: 139500/211692, Loss: 4.1480\n",
            "Epoch: 1, Step: 140000/211692, Loss: 4.1625\n",
            "Epoch: 1, Step: 140000/211692, Acc: 0.2762\n",
            "Epoch: 1, Step: 140500/211692, Loss: 4.1899\n",
            "Epoch: 1, Step: 141000/211692, Loss: 4.1600\n",
            "Epoch: 1, Step: 141000/211692, Acc: 0.2766\n",
            "Epoch: 1, Step: 141500/211692, Loss: 4.1666\n",
            "Epoch: 1, Step: 142000/211692, Loss: 4.1304\n",
            "Epoch: 1, Step: 142000/211692, Acc: 0.2766\n",
            "Epoch: 1, Step: 142500/211692, Loss: 4.1722\n",
            "Epoch: 1, Step: 143000/211692, Loss: 4.1319\n",
            "Epoch: 1, Step: 143000/211692, Acc: 0.2776\n",
            "Epoch: 1, Step: 143500/211692, Loss: 4.1567\n",
            "Epoch: 1, Step: 144000/211692, Loss: 4.1335\n",
            "Epoch: 1, Step: 144000/211692, Acc: 0.2739\n",
            "Epoch: 1, Step: 144500/211692, Loss: 4.1469\n",
            "Epoch: 1, Step: 145000/211692, Loss: 4.1598\n",
            "Epoch: 1, Step: 145000/211692, Acc: 0.2741\n",
            "Epoch: 1, Step: 145500/211692, Loss: 4.1772\n",
            "Epoch: 1, Step: 146000/211692, Loss: 4.1537\n",
            "Epoch: 1, Step: 146000/211692, Acc: 0.2765\n",
            "Epoch: 1, Step: 146500/211692, Loss: 4.1327\n",
            "Epoch: 1, Step: 147000/211692, Loss: 4.1896\n",
            "Epoch: 1, Step: 147000/211692, Acc: 0.2785\n",
            "Epoch: 1, Step: 147500/211692, Loss: 4.1274\n",
            "Epoch: 1, Step: 148000/211692, Loss: 4.1930\n",
            "Epoch: 1, Step: 148000/211692, Acc: 0.2756\n",
            "Epoch: 1, Step: 148500/211692, Loss: 4.1001\n",
            "Epoch: 1, Step: 149000/211692, Loss: 4.1196\n",
            "Epoch: 1, Step: 149000/211692, Acc: 0.2774\n",
            "Epoch: 1, Step: 149500/211692, Loss: 4.1511\n",
            "Epoch: 1, Step: 150000/211692, Loss: 4.1715\n",
            "Epoch: 1, Step: 150000/211692, Acc: 0.2768\n",
            "Epoch: 1, Step: 150500/211692, Loss: 4.1000\n",
            "Epoch: 1, Step: 151000/211692, Loss: 4.1900\n",
            "Epoch: 1, Step: 151000/211692, Acc: 0.2737\n",
            "Epoch: 1, Step: 151500/211692, Loss: 4.0775\n",
            "Epoch: 1, Step: 152000/211692, Loss: 4.0810\n",
            "Epoch: 1, Step: 152000/211692, Acc: 0.2772\n",
            "Epoch: 1, Step: 152500/211692, Loss: 4.1788\n",
            "Epoch: 1, Step: 153000/211692, Loss: 4.1526\n",
            "Epoch: 1, Step: 153000/211692, Acc: 0.2739\n",
            "Epoch: 1, Step: 153500/211692, Loss: 4.1432\n",
            "Epoch: 1, Step: 154000/211692, Loss: 4.1725\n",
            "Epoch: 1, Step: 154000/211692, Acc: 0.2771\n",
            "Epoch: 1, Step: 154500/211692, Loss: 4.1352\n",
            "Epoch: 1, Step: 155000/211692, Loss: 4.1869\n",
            "Epoch: 1, Step: 155000/211692, Acc: 0.2747\n",
            "Epoch: 1, Step: 155500/211692, Loss: 4.0870\n",
            "Epoch: 1, Step: 156000/211692, Loss: 4.0699\n",
            "Epoch: 1, Step: 156000/211692, Acc: 0.2770\n",
            "Epoch: 1, Step: 156500/211692, Loss: 4.1186\n",
            "Epoch: 1, Step: 157000/211692, Loss: 4.1834\n",
            "Epoch: 1, Step: 157000/211692, Acc: 0.2760\n",
            "Epoch: 1, Step: 157500/211692, Loss: 4.0907\n",
            "Epoch: 1, Step: 158000/211692, Loss: 4.1278\n",
            "Epoch: 1, Step: 158000/211692, Acc: 0.2759\n",
            "Epoch: 1, Step: 158500/211692, Loss: 4.1708\n",
            "Epoch: 1, Step: 159000/211692, Loss: 4.1176\n",
            "Epoch: 1, Step: 159000/211692, Acc: 0.2746\n",
            "Epoch: 1, Step: 159500/211692, Loss: 4.1662\n",
            "Epoch: 1, Step: 160000/211692, Loss: 4.1368\n",
            "Epoch: 1, Step: 160000/211692, Acc: 0.2778\n",
            "Epoch: 1, Step: 160500/211692, Loss: 4.2031\n",
            "Epoch: 1, Step: 161000/211692, Loss: 4.1242\n",
            "Epoch: 1, Step: 161000/211692, Acc: 0.2752\n",
            "Epoch: 1, Step: 161500/211692, Loss: 4.1139\n",
            "Epoch: 1, Step: 162000/211692, Loss: 4.1251\n",
            "Epoch: 1, Step: 162000/211692, Acc: 0.2754\n",
            "Epoch: 1, Step: 162500/211692, Loss: 4.1242\n",
            "Epoch: 1, Step: 163000/211692, Loss: 4.2181\n",
            "Epoch: 1, Step: 163000/211692, Acc: 0.2765\n",
            "Epoch: 1, Step: 163500/211692, Loss: 4.1277\n",
            "Epoch: 1, Step: 164000/211692, Loss: 4.1184\n",
            "Epoch: 1, Step: 164000/211692, Acc: 0.2761\n",
            "Epoch: 1, Step: 164500/211692, Loss: 4.1212\n",
            "Epoch: 1, Step: 165000/211692, Loss: 4.1354\n",
            "Epoch: 1, Step: 165000/211692, Acc: 0.2746\n",
            "Epoch: 1, Step: 165500/211692, Loss: 4.1726\n",
            "Epoch: 1, Step: 166000/211692, Loss: 4.1207\n",
            "Epoch: 1, Step: 166000/211692, Acc: 0.2770\n",
            "Epoch: 1, Step: 166500/211692, Loss: 4.0932\n",
            "Epoch: 1, Step: 167000/211692, Loss: 4.1052\n",
            "Epoch: 1, Step: 167000/211692, Acc: 0.2754\n",
            "Epoch: 1, Step: 167500/211692, Loss: 4.1420\n",
            "Epoch: 1, Step: 168000/211692, Loss: 4.1153\n",
            "Epoch: 1, Step: 168000/211692, Acc: 0.2769\n",
            "Epoch: 1, Step: 168500/211692, Loss: 4.1353\n",
            "Epoch: 1, Step: 169000/211692, Loss: 4.1382\n",
            "Epoch: 1, Step: 169000/211692, Acc: 0.2749\n",
            "Epoch: 1, Step: 169500/211692, Loss: 4.1116\n",
            "Epoch: 1, Step: 170000/211692, Loss: 4.1692\n",
            "Epoch: 1, Step: 170000/211692, Acc: 0.2771\n",
            "Epoch: 1, Step: 170500/211692, Loss: 4.1131\n",
            "Epoch: 1, Step: 171000/211692, Loss: 4.1755\n",
            "Epoch: 1, Step: 171000/211692, Acc: 0.2769\n",
            "Epoch: 1, Step: 171500/211692, Loss: 4.0936\n",
            "Epoch: 1, Step: 172000/211692, Loss: 4.1215\n",
            "Epoch: 1, Step: 172000/211692, Acc: 0.2769\n",
            "Epoch: 1, Step: 172500/211692, Loss: 4.0700\n",
            "Epoch: 1, Step: 173000/211692, Loss: 4.0623\n",
            "Epoch: 1, Step: 173000/211692, Acc: 0.2736\n",
            "Epoch: 1, Step: 173500/211692, Loss: 4.0819\n",
            "Epoch: 1, Step: 174000/211692, Loss: 4.1035\n",
            "Epoch: 1, Step: 174000/211692, Acc: 0.2769\n",
            "Epoch: 1, Step: 174500/211692, Loss: 4.1751\n",
            "Epoch: 1, Step: 175000/211692, Loss: 4.1356\n",
            "Epoch: 1, Step: 175000/211692, Acc: 0.2763\n",
            "Epoch: 1, Step: 175500/211692, Loss: 4.1472\n",
            "Epoch: 1, Step: 176000/211692, Loss: 4.1631\n",
            "Epoch: 1, Step: 176000/211692, Acc: 0.2762\n",
            "Epoch: 1, Step: 176500/211692, Loss: 4.1052\n",
            "Epoch: 1, Step: 177000/211692, Loss: 4.1326\n",
            "Epoch: 1, Step: 177000/211692, Acc: 0.2755\n",
            "Epoch: 1, Step: 177500/211692, Loss: 4.1061\n",
            "Epoch: 1, Step: 178000/211692, Loss: 4.1640\n",
            "Epoch: 1, Step: 178000/211692, Acc: 0.2742\n",
            "Epoch: 1, Step: 178500/211692, Loss: 4.1460\n",
            "Epoch: 1, Step: 179000/211692, Loss: 4.0803\n",
            "Epoch: 1, Step: 179000/211692, Acc: 0.2773\n",
            "Epoch: 1, Step: 179500/211692, Loss: 4.1246\n",
            "Epoch: 1, Step: 180000/211692, Loss: 4.1390\n",
            "Epoch: 1, Step: 180000/211692, Acc: 0.2759\n",
            "Epoch: 1, Step: 180500/211692, Loss: 4.0910\n",
            "Epoch: 1, Step: 181000/211692, Loss: 4.1018\n",
            "Epoch: 1, Step: 181000/211692, Acc: 0.2747\n",
            "Epoch: 1, Step: 181500/211692, Loss: 4.1169\n",
            "Epoch: 1, Step: 182000/211692, Loss: 4.1076\n",
            "Epoch: 1, Step: 182000/211692, Acc: 0.2766\n",
            "Epoch: 1, Step: 182500/211692, Loss: 4.1137\n",
            "Epoch: 1, Step: 183000/211692, Loss: 4.0901\n",
            "Epoch: 1, Step: 183000/211692, Acc: 0.2741\n",
            "Epoch: 1, Step: 183500/211692, Loss: 4.1623\n",
            "Epoch: 1, Step: 184000/211692, Loss: 4.1178\n",
            "Epoch: 1, Step: 184000/211692, Acc: 0.2745\n",
            "Epoch: 1, Step: 184500/211692, Loss: 4.0987\n",
            "Epoch: 1, Step: 185000/211692, Loss: 4.1879\n",
            "Epoch: 1, Step: 185000/211692, Acc: 0.2768\n",
            "Epoch: 1, Step: 185500/211692, Loss: 4.1337\n",
            "Epoch: 1, Step: 186000/211692, Loss: 4.1347\n",
            "Epoch: 1, Step: 186000/211692, Acc: 0.2770\n",
            "Epoch: 1, Step: 186500/211692, Loss: 4.1512\n",
            "Epoch: 1, Step: 187000/211692, Loss: 4.1157\n",
            "Epoch: 1, Step: 187000/211692, Acc: 0.2755\n",
            "Epoch: 1, Step: 187500/211692, Loss: 4.1288\n",
            "Epoch: 1, Step: 188000/211692, Loss: 4.1206\n",
            "Epoch: 1, Step: 188000/211692, Acc: 0.2767\n",
            "Epoch: 1, Step: 188500/211692, Loss: 4.0654\n",
            "Epoch: 1, Step: 189000/211692, Loss: 4.1518\n",
            "Epoch: 1, Step: 189000/211692, Acc: 0.2765\n",
            "Epoch: 1, Step: 189500/211692, Loss: 4.1173\n",
            "Epoch: 1, Step: 190000/211692, Loss: 4.0840\n",
            "Epoch: 1, Step: 190000/211692, Acc: 0.2733\n",
            "Epoch: 1, Step: 190500/211692, Loss: 4.1195\n",
            "Epoch: 1, Step: 191000/211692, Loss: 4.1746\n",
            "Epoch: 1, Step: 191000/211692, Acc: 0.2759\n",
            "Epoch: 1, Step: 191500/211692, Loss: 4.1244\n",
            "Epoch: 1, Step: 192000/211692, Loss: 4.1310\n",
            "Epoch: 1, Step: 192000/211692, Acc: 0.2779\n",
            "Epoch: 1, Step: 192500/211692, Loss: 4.0741\n",
            "Epoch: 1, Step: 193000/211692, Loss: 4.1219\n",
            "Epoch: 1, Step: 193000/211692, Acc: 0.2756\n",
            "Epoch: 1, Step: 193500/211692, Loss: 4.1449\n",
            "Epoch: 1, Step: 194000/211692, Loss: 4.1071\n",
            "Epoch: 1, Step: 194000/211692, Acc: 0.2775\n",
            "Epoch: 1, Step: 194500/211692, Loss: 4.1099\n",
            "Epoch: 1, Step: 195000/211692, Loss: 4.0960\n",
            "Epoch: 1, Step: 195000/211692, Acc: 0.2753\n",
            "Epoch: 1, Step: 195500/211692, Loss: 4.0904\n",
            "Epoch: 1, Step: 196000/211692, Loss: 4.1679\n",
            "Epoch: 1, Step: 196000/211692, Acc: 0.2777\n",
            "Epoch: 1, Step: 196500/211692, Loss: 4.0787\n",
            "Epoch: 1, Step: 197000/211692, Loss: 4.0973\n",
            "Epoch: 1, Step: 197000/211692, Acc: 0.2781\n",
            "Epoch: 1, Step: 197500/211692, Loss: 4.1900\n",
            "Epoch: 1, Step: 198000/211692, Loss: 4.1032\n",
            "Epoch: 1, Step: 198000/211692, Acc: 0.2770\n",
            "Epoch: 1, Step: 198500/211692, Loss: 4.1153\n",
            "Epoch: 1, Step: 199000/211692, Loss: 4.1047\n",
            "Epoch: 1, Step: 199000/211692, Acc: 0.2768\n",
            "Epoch: 1, Step: 199500/211692, Loss: 4.1356\n",
            "Epoch: 1, Step: 200000/211692, Loss: 4.0819\n",
            "Epoch: 1, Step: 200000/211692, Acc: 0.2775\n",
            "Epoch: 1, Step: 200500/211692, Loss: 4.1173\n",
            "Epoch: 1, Step: 201000/211692, Loss: 4.1340\n",
            "Epoch: 1, Step: 201000/211692, Acc: 0.2750\n",
            "Epoch: 1, Step: 201500/211692, Loss: 4.1264\n",
            "Epoch: 1, Step: 202000/211692, Loss: 4.1295\n",
            "Epoch: 1, Step: 202000/211692, Acc: 0.2752\n",
            "Epoch: 1, Step: 202500/211692, Loss: 4.1352\n",
            "Epoch: 1, Step: 203000/211692, Loss: 4.0761\n",
            "Epoch: 1, Step: 203000/211692, Acc: 0.2752\n",
            "Epoch: 1, Step: 203500/211692, Loss: 4.1184\n",
            "Epoch: 1, Step: 204000/211692, Loss: 4.1413\n",
            "Epoch: 1, Step: 204000/211692, Acc: 0.2759\n",
            "Epoch: 1, Step: 204500/211692, Loss: 4.1747\n",
            "Epoch: 1, Step: 205000/211692, Loss: 4.1101\n",
            "Epoch: 1, Step: 205000/211692, Acc: 0.2761\n",
            "Epoch: 1, Step: 205500/211692, Loss: 4.0926\n",
            "Epoch: 1, Step: 206000/211692, Loss: 4.2063\n",
            "Epoch: 1, Step: 206000/211692, Acc: 0.2768\n",
            "Epoch: 1, Step: 206500/211692, Loss: 4.1150\n",
            "Epoch: 1, Step: 207000/211692, Loss: 4.1500\n",
            "Epoch: 1, Step: 207000/211692, Acc: 0.2767\n",
            "Epoch: 1, Step: 207500/211692, Loss: 4.0955\n",
            "Epoch: 1, Step: 208000/211692, Loss: 4.0933\n",
            "Epoch: 1, Step: 208000/211692, Acc: 0.2757\n",
            "Epoch: 1, Step: 208500/211692, Loss: 4.1340\n",
            "Epoch: 1, Step: 209000/211692, Loss: 4.1426\n",
            "Epoch: 1, Step: 209000/211692, Acc: 0.2760\n",
            "Epoch: 1, Step: 209500/211692, Loss: 4.1455\n",
            "Epoch: 1, Step: 210000/211692, Loss: 4.1115\n",
            "Epoch: 1, Step: 210000/211692, Acc: 0.2770\n",
            "Epoch: 1, Step: 210500/211692, Loss: 4.1103\n",
            "Epoch: 1, Step: 211000/211692, Loss: 4.0760\n",
            "Epoch: 1, Step: 211000/211692, Acc: 0.2757\n",
            "Epoch: 1, Step: 211500/211692, Loss: 4.0858\n",
            "Epoch: 1, Accuracy: 0.2774\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(1, 2):\n",
        "    train(epoch)\n",
        "    acc = test()\n",
        "    print(f'Epoch: {epoch}, Accuracy: {acc:.4f}')\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcH1SbRTbNOp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBr4NkvYbNOp"
      },
      "source": [
        "# load the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "p9onzvzebNOp"
      },
      "outputs": [],
      "source": [
        "loaded_model = MetaPath2Vec(data.edge_index_dict,\n",
        "                     embedding_dim=64,\n",
        "                     metapath=metapath,\n",
        "                     walk_length=3,\n",
        "                     context_size=3,\n",
        "                     walks_per_node=2,\n",
        "                     num_negative_samples=1,\n",
        "                     sparse=True\n",
        "                    ).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5qYbf26GbNOp",
        "outputId": "baaba6a1-8786-47e4-cc72-3c36696d2706",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.6314,  1.3194,  0.5600,  0.7705,  0.2499], grad_fn=<SliceBackward0>)\n"
          ]
        }
      ],
      "source": [
        "print(loaded_model.embedding.weight[1][:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEjHSOI1bNOp"
      },
      "outputs": [],
      "source": [
        "# load the model\n",
        "loaded_model.load_state_dict(torch.load(\"mymodel\").detach().cpu())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBwKfKitbNOq"
      },
      "outputs": [],
      "source": [
        "# move the model to cpu\n",
        "file = torch.load('mymodel', map_location=lambda storage, loc: storage)\n",
        "loaded_model.load_state_dict(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMVTX48hbNOq"
      },
      "outputs": [],
      "source": [
        "print(loaded_model.embedding.weight[1][:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "UdDLSIR6bNOq"
      },
      "outputs": [],
      "source": [
        "z_venue = loaded_model('venue', batch=data.y_index_dict['venue']).detach().numpy()\n",
        "z_auth = loaded_model('author', batch=data.y_index_dict['author']).detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "3IVIOzbZbNOq"
      },
      "outputs": [],
      "source": [
        "z_venue = z_venue[0:100]\n",
        "z_auth = z_auth[0:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "VmvG3vPybNOr",
        "outputId": "20314d14-1b0f-4ebf-837d-85404c7787b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.10/dist-packages (0.5.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.6.0)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (0.60.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (0.5.13)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from umap-learn) (4.67.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn) (0.43.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from pynndescent>=0.5->umap-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->umap-learn) (3.5.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "!pip install umap-learn\n",
        "import umap\n",
        "\n",
        "# embedder = umap.UMAP().fit(data,y)\n",
        "\n",
        "z_venue_2d = umap.UMAP().fit_transform(z_venue)\n",
        "z_auth_2d = umap.UMAP().fit_transform(z_auth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTeG6T_ibNOr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "wIlGixepbNOr",
        "outputId": "7f6003d8-3ad7-4403-8e03-982579b87a5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(z_auth_2d[:,0],z_auth_2d[:,1],color=\"red\",alpha=0.5,label=\"author\")\n",
        "plt.scatter(z_venue_2d[:,0],z_venue_2d[:,1],color=\"blue\",alpha=0.5,label=\"venue\")\n",
        "plt.legend()\n",
        "plt.title(\"2D embedding\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}